{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LNN SageMaker Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/flaviagiammarino/lnn-sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create the SageMaker Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Create the training image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "algorithm_name=lnn-sagemaker-training\n",
    "algorithm_region=eu-west-1\n",
    "\n",
    "cd amazon_sagemaker_algorithm/training_image\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${algorithm_region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "$(aws ecr get-login --region ${algorithm_region} --no-include-email)\n",
    "\n",
    "$(aws ecr get-login --registry-ids 763104351884 --region us-east-1 --no-include-email)\n",
    "\n",
    "docker build  -t ${algorithm_name} . --build-arg REGION=${algorithm_region}\n",
    "\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Create the inference image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "algorithm_name=lnn-sagemaker-inference\n",
    "algorithm_region=eu-west-1\n",
    "\n",
    "cd amazon_sagemaker_algorithm/i_image\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${algorithm_region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "$(aws ecr get-login --region ${algorithm_region} --no-include-email)\n",
    "\n",
    "$(aws ecr get-login --registry-ids 763104351884 --region us-east-1 --no-include-email)\n",
    "\n",
    "docker build  -t ${algorithm_name} . --build-arg REGION=${algorithm_region}\n",
    "\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import datetime\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SageMaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "\n",
    "# EC2 instance\n",
    "instance_type = \"ml.m5.2xlarge\"\n",
    "\n",
    "# fixed hyperparameters\n",
    "context_length = 200     # number of timesteps used as input\n",
    "prediction_length = 100  # number of timesteps to output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Training dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset = pd.read_csv(\"sample_data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len([c for c in training_dataset.columns if c != \"ts\"]), ncols=1, sharex=True, figsize=(6, 8))\n",
    "for i, c in enumerate([c for c in training_dataset.columns if c != \"ts\"]):\n",
    "    axs[i].plot(training_dataset[c], color=\"#7f8ea3\", lw=1)\n",
    "    axs[i].set_title(c, size=10)\n",
    "    axs[i].set(xlabel=\"Time\", ylabel=\"Value\")\n",
    "    axs[i].xaxis.set_tick_params(labelbottom=True)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"minor\", labelsize=7)\n",
    "fig.suptitle(\"Training Dataset\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data = sagemaker_session.upload_string_as_file_body(\n",
    "    body=training_dataset.to_csv(index=False),\n",
    "    bucket=bucket,\n",
    "    key=\"data/training/train.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_dataset = pd.read_csv(\"sample_data/valid.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len([c for c in validation_dataset.columns if c != \"ts\"]), ncols=1, sharex=True, figsize=(6, 8))\n",
    "for i, c in enumerate([c for c in validation_dataset.columns if c != \"ts\"]):\n",
    "    axs[i].plot(validation_dataset[c], color=\"#7f8ea3\", lw=1)\n",
    "    axs[i].set_title(c, size=10)\n",
    "    axs[i].set(xlabel=\"Time\", ylabel=\"Value\")\n",
    "    axs[i].xaxis.set_tick_params(labelbottom=True)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"minor\", labelsize=7)\n",
    "fig.suptitle(\"Validation Dataset\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data = sagemaker_session.upload_string_as_file_body(\n",
    "    body=validation_dataset.to_csv(index=False),\n",
    "    bucket=bucket,\n",
    "    key=\"data/training/valid.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"sample_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len([c for c in test_dataset.columns if c != \"ts\"]), ncols=1, sharex=True, figsize=(6, 8))\n",
    "for i, c in enumerate([c for c in test_dataset.columns if c != \"ts\"]):\n",
    "    axs[i].plot(test_dataset[c], color=\"#7f8ea3\", lw=1)\n",
    "    axs[i].set_title(c, size=10)\n",
    "    axs[i].set(xlabel=\"Time\", ylabel=\"Value\")\n",
    "    axs[i].xaxis.set_tick_params(labelbottom=True)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"minor\", labelsize=7)\n",
    "fig.suptitle(\"Test Dataset\")\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = sagemaker_session.upload_string_as_file_body(\n",
    "    body=test_dataset.to_csv(index=False),\n",
    "    bucket=bucket,\n",
    "    key=\"data/inference/input/test.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train a machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"context-length\": context_length,\n",
    "    \"prediction-length\": prediction_length,\n",
    "    \"sequence-stride\": 1,\n",
    "    \"backbone-layers\": 1,\n",
    "    \"backbone-units\": 128,\n",
    "    \"backbone-activation\": \"silu\",\n",
    "    \"backbone-dropout\": 0,\n",
    "    \"hidden-size\": 64,\n",
    "    \"minimal\": 0,\n",
    "    \"no-gate\": 0,\n",
    "    \"use-ltc\": 0,\n",
    "    \"use-mixed\": 0,\n",
    "    \"lr\": 0.001,\n",
    "    \"lr-decay\": 0.999,\n",
    "    \"batch-size\": 64,\n",
    "    \"epochs\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "    # metrics logged to CloudWatch during training\n",
    "    {\"Name\": \"training_mse\", \"Regex\": \"train_mse: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation_mse\", \"Regex\": \"valid_mse: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"training_mae\", \"Regex\": \"train_mae: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation_mae\", \"Regex\": \"valid_mae: ([0-9\\\\.]+)\"},\n",
    "    # metrics logged to CloudWatch at the end of training\n",
    "    {\"Name\": \"train:mse\", \"Regex\": \"train:mse ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"valid:mse\", \"Regex\": \"valid:mse ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"train:mae\", \"Regex\": \"train:mae ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"valid:mae\", \"Regex\": \"valid:mae ([0-9\\\\.]+)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see the [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = sagemaker.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"lnn-training\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    input_mode=\"File\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": training_data, \"validation\": validation_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incremental Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator = sagemaker.algorithm.AlgorithmEstimator(\n",
    "    model_uri=f's3://{bucket}/{estimator.latest_training_job.name}/output/model.tar.gz',\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name=\"lnn-fine-tuning\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    input_mode=\"File\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions\n",
    ")\n",
    "\n",
    "estimator.fit({\"training\": training_data, \"validation\": validation_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "serializer = sagemaker.serializers.CSVSerializer(content_type=\"text/csv\")\n",
    "deserializer = sagemaker.base_deserializers.PandasDeserializer(accept=\"text/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Deploy trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    model_name=f\"lnn-model-{datetime.datetime.now().strftime(format='%Y-%m-%d-%H-%M-%S-%f')}\",\n",
    "    endpoint_name=f\"lnn-endpoint-{datetime.datetime.now().strftime(format='%Y-%m-%d-%H-%M-%S-%f')}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the endpoint is in service, you can perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference algorithm takes as input a CSV file containing the time series. The CSV file should have the same format as the one used for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the test dataset used in this experiment is relatively small, we invoke the endpoint using all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "payload = test_dataset.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = sagemaker_session.sagemaker_runtime_client.invoke_endpoint(\n",
    "    EndpointName=predictor.endpoint_name,\n",
    "    ContentType=\"text/csv\",\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "real_time_predictions = deserializer.deserialize(response[\"Body\"], content_type=\"text/csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_time_results = sagemaker_session.upload_string_as_file_body(\n",
    "    body=real_time_predictions.to_csv(index=False),\n",
    "    bucket=bucket,\n",
    "    key=\"data/inference/output/real-time/real_time_predictions.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_time_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Visualize output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference algorithm outputs the predicted values of the time series and the standard deviation of the predictions. \n",
    "\n",
    "**Notes:** \n",
    "\n",
    "a) The model predicts the time series sequence by sequence. For instance, if the `context-length` is set equal to 200, and the `prediction-length` is set equal to 100, then the first 200 data points (from 1 to 200) are used as input to predict the next 100 data points (from 201 to 300). As a result, the algorithm does not return the predicted values of the first 200 data points, which are set to missing in the output CSV file.\n",
    "\n",
    "b) The outputs include the out-of-sample forecasts beyond the last time step of the inputs. For instance, if the number of input samples is 500, and the `prediction-length` is 100, then the output CSV file will contain 600 samples, where the last 100 samples are the out-of-sample forecasts.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_time_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_time_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_time_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "real_time_predictions.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len([c for c in test_dataset.columns if c.startswith(\"y\")]), ncols=1, sharex=True, figsize=(6, 5))\n",
    "for i, c in enumerate([c for c in test_dataset.columns if c.startswith(\"y\")]):\n",
    "    axs[i].plot(test_dataset.index, test_dataset[c].values, color=\"#7f8ea3\", lw=1, label=\"Actual\" if i == 0 else None)\n",
    "    axs[i].plot(real_time_predictions.index, real_time_predictions[f\"{c}_mean\"].values, color=\"#009ad3\", lw=1, label=\"Predicted\" if i == 0 else None)\n",
    "    axs[i].fill_between(real_time_predictions.index, real_time_predictions[f\"{c}_mean\"].values + real_time_predictions[f\"{c}_std\"].values, real_time_predictions[f\"{c}_mean\"].values - real_time_predictions[f\"{c}_std\"].values, color=\"#009ad3\", alpha=0.2, lw=1, label=\"Predicted +/- 1 Std. Dev.\" if i == 0 else None)\n",
    "    axs[i].fill_between(real_time_predictions.index, real_time_predictions[f\"{c}_mean\"].values + 2 * real_time_predictions[f\"{c}_std\"].values, real_time_predictions[f\"{c}_mean\"].values - 2 * real_time_predictions[f\"{c}_std\"].values, color=\"#009ad3\", alpha=0.1, lw=1, label=\"Predicted +/- 2 Std. Dev.\" if i == 0 else None)\n",
    "    axs[i].set_title(c, size=10)\n",
    "    axs[i].set(xlabel=\"Time\", ylabel=\"Value\")\n",
    "    axs[i].xaxis.set_tick_params(labelbottom=True)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"minor\", labelsize=7)\n",
    "fig.suptitle(\"Real Time Predictions on Test Dataset\")\n",
    "fig.legend(bbox_to_anchor=(1, 0, 0.4, 1), frameon=False)\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Calculate relevant metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we assess the model's forecasting performance against the ground truth time series values. Note that in this section we calculate the mean squared error (MSE) and mean absolute error (MAE) separately for each time series using unscaled data. These are different from the metrics returned by the algorithm, which are the average MSE and MAE across all time series calculated using scaled data.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for c in [c for c in test_dataset.columns if c.startswith(\"y\")]:\n",
    "    mse = mean_squared_error(test_dataset[c].iloc[context_length:], real_time_predictions[f\"{c}_mean\"].iloc[context_length: - prediction_length])\n",
    "    mae = mean_absolute_error(test_dataset[c].iloc[context_length:], real_time_predictions[f\"{c}_mean\"].iloc[context_length: -prediction_length])\n",
    "    print(f\"Time series: {c}, MSE: {format(mse, '.2f')}, MAE: {format(mae, '.2f')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If [Amazon SageMaker Model Monitor](https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor.html) supports the type of problem you are trying to solve using this algorithm, use the following examples to add Model Monitor support to your product.\n",
    "For sample code to enable and monitor the model, see following notebooks:\n",
    "1. [Enable Amazon SageMaker Model Monitor](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker_model_monitor/enable_model_monitor/SageMaker-Enable-Model-Monitor.ipynb)\n",
    "2. [Amazon SageMaker Model Monitor - visualizing monitoring results](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/sagemaker_model_monitor/visualization/SageMaker-Model-Monitor-Visualize.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the same to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is an experiment, you do not need to run a hyperparameter tuning job. However, if you would like to see how to tune a model trained using a third-party algorithm with Amazon SageMaker's hyperparameter tuning functionality, you can run the optional tuning step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Tune your model! (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Tuning guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has the following hyperparameters, all of which are tunable:\n",
    "- `context-length`: `int`. The length of the input sequences.\n",
    "- `prediction-length`: `int`. The length of the output sequences.\n",
    "- `sequence-stride`: `int`. The period between consecutive output sequences.\n",
    "- `backbone-layers`: `int`. The number of hidden layers of the backbone neural network. \n",
    "- `backbone-units`: `int`. The number of hidden units of the backbone neural network.\n",
    "- `backbone-activation`: `str`. The activation function of the backbone neural network.\n",
    "- `backbone-dropout`: `float`. The dropout rate of the backbone neural network.\n",
    "- `hidden-size`: `int`. The number of hidden units of the neural network heads.\n",
    "- `minimal`: `bool`. If set to 1, the model will use the CfC direct solution.\n",
    "- `no-gate`: `bool`. If set to 1, the model will use a CfC without the (1 - sigmoid) part.\n",
    "- `use-ltc`: `bool`. If set to 1, the model will use an LTC instead of a CfC.\n",
    "- `use-mixed`: `bool`. If set to 1, the model will mix the CfC RNN-state with an LSTM.\n",
    "- `lr`: `float`. The learning rate used for training.\n",
    "- `lr-decay`: `float`. The decay factor applied to the learning rate.\n",
    "- `batch-size`: `int`. The batch size used for training.\n",
    "- `epochs`: `int`. The number of training epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Define tuning configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges = {\n",
    "    \"backbone-layers\": sagemaker.parameter.IntegerParameter(1, 3),\n",
    "    \"backbone-units\": sagemaker.parameter.CategoricalParameter([32, 64, 128, 256]),\n",
    "    \"backbone-activation\": sagemaker.parameter.CategoricalParameter([\"silu\", \"relu\", \"tanh\", \"gelu\", \"lecun\"]),\n",
    "    \"backbone-dropout\": sagemaker.parameter.ContinuousParameter(0, 0.5),\n",
    "    \"hidden-size\": sagemaker.parameter.CategoricalParameter([32, 64, 128, 256]),\n",
    "    \"lr\": sagemaker.parameter.ContinuousParameter(0.0001, 0.01),\n",
    "    \"lr-decay\": sagemaker.parameter.ContinuousParameter(0.9, 1.0),\n",
    "    \"batch-size\": sagemaker.parameter.CategoricalParameter([32, 64, 128, 256]),\n",
    "    \"epochs\": sagemaker.parameter.IntegerParameter(20, 200),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the validation mean absolute error (MAE) as the objective to be minimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_metric_name = \"valid_mae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_type = \"Minimize\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Run a model tuning job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to detach the pre-trained model before tuning, otherwise the algorithm will keep using the same hyperparameters with the exception of the batch size, learning rate decay factor and number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimator.model_uri = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interest of time, we run the tuner only for a few iterations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    base_tuning_job_name=\"lnn-tuning\",\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    objective_type=objective_type,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    max_jobs=4,\n",
    "    max_parallel_jobs=4,\n",
    "    random_seed=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner.fit({\"training\": training_data, \"validation\": validation_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuner.analytics().dataframe().sort_values(by=\"FinalObjectiveValue\", ascending=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tuning_job_result = sagemaker_session.sagemaker_client.describe_hyper_parameter_tuning_job(\n",
    "    HyperParameterTuningJobName=tuner.latest_tuning_job.name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Best hyperparameters:\")\n",
    "tuning_job_result[\"BestTrainingJob\"][\"TunedHyperParameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Best score:\")\n",
    "tuning_job_result[\"BestTrainingJob\"][\"FinalHyperParameterTuningJobObjectiveMetric\"][\"Value\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have completed a tuning job (or even while the job is still running), you can [clone and use this notebook](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/hyperparameter_tuning/analyze_results/HPO_Analyze_TuningJob_Results.ipynb) to analyze the results to understand how each hyperparameter effects the quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer.base_transform_job_name = \"lnn-transform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer.transform(\n",
    "    data=test_data,\n",
    "    content_type=\"text/csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_predictions = sagemaker_session.read_s3_file(\n",
    "    bucket=bucket,\n",
    "    key_prefix=f\"{transformer.latest_transform_job.name}/test.csv.out\"\n",
    ")\n",
    "\n",
    "batch_predictions = pd.read_csv(io.StringIO(batch_predictions), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_predictions.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_predictions.isna().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.all(np.isclose(batch_predictions.dropna().values, real_time_predictions.dropna().values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=len([c for c in test_dataset.columns if c.startswith(\"y\")]), ncols=1, sharex=True, figsize=(6, 5))\n",
    "for i, c in enumerate([c for c in test_dataset.columns if c.startswith(\"y\")]):\n",
    "    axs[i].plot(test_dataset.index, test_dataset[c].values, color=\"#7f8ea3\", lw=1, label=\"Actual\" if i == 0 else None)\n",
    "    axs[i].plot(batch_predictions.index, batch_predictions[f\"{c}_mean\"].values, color=\"#009ad3\", lw=1, label=\"Predicted\" if i == 0 else None)\n",
    "    axs[i].fill_between(batch_predictions.index, batch_predictions[f\"{c}_mean\"].values + batch_predictions[f\"{c}_std\"].values, batch_predictions[f\"{c}_mean\"].values - batch_predictions[f\"{c}_std\"].values, color=\"#009ad3\", alpha=0.2, lw=1, label=\"Predicted +/- 1 Std. Dev.\" if i == 0 else None)\n",
    "    axs[i].fill_between(batch_predictions.index, batch_predictions[f\"{c}_mean\"].values + 2 * batch_predictions[f\"{c}_std\"].values, batch_predictions[f\"{c}_mean\"].values - 2 * batch_predictions[f\"{c}_std\"].values, color=\"#009ad3\", alpha=0.1, lw=1, label=\"Predicted +/- 2 Std. Dev.\" if i == 0 else None)\n",
    "    axs[i].set_title(c, size=10)\n",
    "    axs[i].set(xlabel=\"Time\", ylabel=\"Value\")\n",
    "    axs[i].xaxis.set_tick_params(labelbottom=True)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"major\", labelsize=7)\n",
    "    axs[i].tick_params(axis=\"both\", which=\"minor\", labelsize=7)\n",
    "fig.suptitle(\"Batch Predictions on Test Dataset\")\n",
    "fig.legend(bbox_to_anchor=(1, 0, 0.4, 1), frameon=False)\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_results = sagemaker_session.upload_string_as_file_body(\n",
    "    body=batch_predictions.to_csv(index=False),\n",
    "    bucket=bucket,\n",
    "    key=\"data/inference/output/batch/batch_predictions.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
